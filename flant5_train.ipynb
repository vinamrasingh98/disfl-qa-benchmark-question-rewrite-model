{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Flant5 Train\n","Training file to fine-tune the flan-t5 base model. Flan-T5 is a variant of the T5 (Text-To-Text Transfer Transformer) model that has been fine-tuned using the FLAN (Fine-tuned Language Net) methodology."]},{"cell_type":"markdown","metadata":{},"source":["#### Step 1: Install Required Dependencies"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T17:49:56.547246Z","iopub.status.busy":"2024-08-29T17:49:56.546889Z","iopub.status.idle":"2024-08-29T17:50:39.305480Z","shell.execute_reply":"2024-08-29T17:50:39.304513Z","shell.execute_reply.started":"2024-08-29T17:49:56.547210Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting evaluate\n","  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n","Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.21.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.4)\n","Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n","Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.24.6)\n","Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.15.1)\n","Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (16.1.0)\n","Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.5)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.7.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n","Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n","\u001b[?25hInstalling collected packages: evaluate\n","Successfully installed evaluate-0.4.2\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m825.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hCollecting portalocker (from sacrebleu)\n","  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\n","Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\n","Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n","Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\n","Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n","Installing collected packages: portalocker, sacrebleu\n","Successfully installed portalocker-2.10.1 sacrebleu-2.4.3\n","Collecting bert-score\n","  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n","Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.4.0)\n","Requirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.2.2)\n","Requirement already satisfied: transformers>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.44.0)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bert-score) (1.26.4)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from bert-score) (2.32.3)\n","Requirement already satisfied: tqdm>=4.31.1 in /opt/conda/lib/python3.10/site-packages (from bert-score) (4.66.4)\n","Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from bert-score) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->bert-score) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n","Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score) (2024.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (4.12.2)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (1.13.2)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (3.1.4)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->bert-score) (2024.6.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.24.6)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (2024.5.15)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.4.4)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers>=3.0.0->bert-score) (0.19.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\n","Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (9.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->bert-score) (2024.7.4)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert-score) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->bert-score) (2.1.5)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->bert-score) (1.3.0)\n","Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m901.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m--:--\u001b[0m\n","\u001b[?25hInstalling collected packages: bert-score\n","Successfully installed bert-score-0.3.13\n"]}],"source":["!pip install evaluate\n","!pip install sacrebleu\n","!pip install bert-score"]},{"cell_type":"markdown","metadata":{},"source":["Load the datasets, Large Language Model (LLM) and tokenizer."]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T17:50:39.307698Z","iopub.status.busy":"2024-08-29T17:50:39.307389Z","iopub.status.idle":"2024-08-29T17:51:02.980707Z","shell.execute_reply":"2024-08-29T17:51:02.979869Z","shell.execute_reply.started":"2024-08-29T17:50:39.307666Z"},"trusted":true},"outputs":[],"source":["import os\n","import torch\n","import numpy as np\n","from datasets import load_dataset\n","import json\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n","import evaluate\n","import bert_score"]},{"cell_type":"markdown","metadata":{},"source":["#### Step 2: Preprocess dataset\n","The restructure_json function processes a list of JSON file names, reads each file, extracts specific fields ('disfluent' and 'original'), and writes the restructured data to new output files. It constructs file paths dynamically and uses JSON operations to read and write the data."]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T17:51:02.982399Z","iopub.status.busy":"2024-08-29T17:51:02.981812Z","iopub.status.idle":"2024-08-29T17:51:02.988831Z","shell.execute_reply":"2024-08-29T17:51:02.987876Z","shell.execute_reply.started":"2024-08-29T17:51:02.982366Z"},"trusted":true},"outputs":[],"source":["def restructure_json(file_names):\n","    \"\"\"\n","    Restructures the JSON files specified by the given list of file names.\n","\n","    Parameters:\n","    file_names (list): A list of file names (without extension) to be processed.\n","\n","    Returns:\n","    None\n","    \"\"\"\n","    for file_name in file_names:\n","        input_path = os.path.join(os.getcwd(), f\"{file_name}.json\")\n","        output_path = os.path.join(os.getcwd(), f\"{file_name}_output.json\")\n","\n","        #print(input_path)\n","        #print(output_path)\n","\n","        with open(input_path, 'r') as f:\n","            raw_data = json.load(f)\n","        #print(raw_data)\n","\n","        dataset = [{'disfluent': item['disfluent'], 'original': item['original']} for item in raw_data.values()]\n","\n","        with open(output_path, 'w') as f:\n","            json.dump(dataset, f, indent=4)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T17:51:02.991728Z","iopub.status.busy":"2024-08-29T17:51:02.991215Z","iopub.status.idle":"2024-08-29T17:51:03.216913Z","shell.execute_reply":"2024-08-29T17:51:03.215924Z","shell.execute_reply.started":"2024-08-29T17:51:02.991681Z"},"trusted":true},"outputs":[],"source":["# Mention the train, dev and test file names without extension and if using holdout datasets, rename the holdout dataset to test dataset\n","# Please make sure that file name defined below should have .json extension\n","file_names = [\"train\", \"dev\", \"test\"]\n","restructure_json(file_names)"]},{"cell_type":"markdown","metadata":{},"source":["Load the preprocessed train, dev and test dataset."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T17:51:03.218679Z","iopub.status.busy":"2024-08-29T17:51:03.218213Z","iopub.status.idle":"2024-08-29T17:51:03.602338Z","shell.execute_reply":"2024-08-29T17:51:03.601422Z","shell.execute_reply.started":"2024-08-29T17:51:03.218589Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"dc247ed497a44f0ab4f80dd933f50a3d","version_major":2,"version_minor":0},"text/plain":["Generating train split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2724f1f8b5ca43fd8a6a8dbe01f95d8f","version_major":2,"version_minor":0},"text/plain":["Generating val split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4178da29b5f48c5a11a3d3000258ac6","version_major":2,"version_minor":0},"text/plain":["Generating test split: 0 examples [00:00, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["data_files = {k: os.path.join(os.getcwd(), f\"{k}_output.json\") for k in [\"train\", \"dev\", \"test\"]}\n","dataset = load_dataset(\"json\", data_files=data_files)"]},{"cell_type":"markdown","metadata":{},"source":["Define your model and tokenizer. Make sure to use the correct model name and tokenizer name"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T17:51:03.603842Z","iopub.status.busy":"2024-08-29T17:51:03.603501Z","iopub.status.idle":"2024-08-29T17:51:11.721566Z","shell.execute_reply":"2024-08-29T17:51:11.720742Z","shell.execute_reply.started":"2024-08-29T17:51:03.603809Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ac676d4699e94e938451b0213bcd2dcd","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"032dd2c6894f41fdb9b912ae7d811914","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"24a5c8bfb3d242fe8c5a5c6d81ef6a8d","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5ee9292453a2410f85706e7cabc16c7a","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7515edc1a3234666a9759682c533fa61","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f575eed1a068455f8d5cc0225c726cdb","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4a12d3f7deeb4b6e854aaa881dd4e5ca","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize the model and tokenizer\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n","model_name = \"google/flan-t5-base\"\n","tokenizer = T5Tokenizer.from_pretrained(model_name, return_tensors=\"pt\")\n","model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)"]},{"cell_type":"markdown","metadata":{},"source":["#### Step 3: Tokenize the input and target\n","Define the function to tokenize disfluent and original questions representing inputs and targets with maximum length "]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T17:51:11.723043Z","iopub.status.busy":"2024-08-29T17:51:11.722736Z","iopub.status.idle":"2024-08-29T17:51:20.099244Z","shell.execute_reply":"2024-08-29T17:51:20.098170Z","shell.execute_reply.started":"2024-08-29T17:51:11.723011Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"61c6f7c273324effb10dd869dd30b34f","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/7182 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cc5f2f9ef1e64504bca215617f57d4ea","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"5af1d1f05486461d89663bed6818cae6","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/3643 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["max_length = 512\n","def tokenize_function(examples):\n","    \"\"\"\n","    Preprocesses the input examples for training a disfluency detection model.\n","\n","    Args:\n","        examples (dict): A dictionary containing the input examples with 'disfluent' and 'original' keys.\n","\n","    Returns:\n","        dict: A dictionary containing the preprocessed model inputs with 'input_ids', 'attention_mask', and 'labels' keys.\n","    \"\"\"\n","\n","    inputs = examples['disfluent']\n","    targets = examples['original']\n","    model_inputs = tokenizer(inputs, max_length = max_length, truncation = True, padding=\"max_length\")\n","    labels = tokenizer(targets, max_length = max_length, truncation = True, padding=\"max_length\")\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","tokenized_data = dataset.map(tokenize_function, batched=True, remove_columns=['disfluent', 'original'])"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T17:51:20.101158Z","iopub.status.busy":"2024-08-29T17:51:20.100761Z","iopub.status.idle":"2024-08-29T17:51:20.105842Z","shell.execute_reply":"2024-08-29T17:51:20.104941Z","shell.execute_reply.started":"2024-08-29T17:51:20.101115Z"},"trusted":true},"outputs":[],"source":["# Data collator to handle dynamic padding and other pre-processing requirements\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"]},{"cell_type":"markdown","metadata":{},"source":["#### Step 4: Define the metric\n","Metric function to evaluate the model. Model is evaluated on sacrebleu and Bert F1 score."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T17:51:20.107216Z","iopub.status.busy":"2024-08-29T17:51:20.106917Z","iopub.status.idle":"2024-08-29T17:51:20.663368Z","shell.execute_reply":"2024-08-29T17:51:20.662420Z","shell.execute_reply.started":"2024-08-29T17:51:20.107184Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b73293034dbe4fdd967d5da4068bb390","version_major":2,"version_minor":0},"text/plain":["Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load BLEU metrics\n","sacrebleu = evaluate.load(\"sacrebleu\")\n","\n","def compute_metrics(eval_pred):\n","    \"\"\"\n","    Compute evaluation metrics for prediction results.\n","    Args:\n","        eval_pred (tuple): A tuple containing predictions and labels.\n","    Returns:\n","        dict: A dictionary containing the computed evaluation metrics.\n","            - \"bleu\" (float): The BLEU score.\n","            - \"Bert Score F1\" (str): The average BERTScore F1 score.\n","    \"\"\"\n","    predictions, labels = eval_pred\n","    # In case the model returns more than the prediction logits\n","    if isinstance(predictions, tuple):\n","        predictions = predictions[0]\n","\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","\n","    # Replace -100 in the labels as we can't decode them\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    decoded_preds = [pred.strip() for pred in decoded_preds]\n","    decoded_labels = [[label.strip()] for label in decoded_labels]  # SacreBLEU expects a list of references for each prediction\n","\n","    sacrebleu_result = sacrebleu.compute(predictions=decoded_preds, references=decoded_labels)\n","\n","    # Calculate BERTScore\n","    P, R, F1 = bert_score.score(decoded_preds, decoded_labels, lang=\"en\", verbose=True)\n","\n","    return {\n","        \"bleu\": sacrebleu_result[\"score\"],\n","        \"Bert Score F1\": f\"{F1.mean().item():.4f}\"\n","    }"]},{"cell_type":"markdown","metadata":{},"source":["#### Step 5: Define the training arguments"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T17:51:20.668092Z","iopub.status.busy":"2024-08-29T17:51:20.666889Z","iopub.status.idle":"2024-08-29T17:51:20.703591Z","shell.execute_reply":"2024-08-29T17:51:20.702867Z","shell.execute_reply.started":"2024-08-29T17:51:20.668056Z"},"trusted":true},"outputs":[],"source":["training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"/output/\",\n","    eval_strategy=\"epoch\",\n","    per_device_train_batch_size=4,\n","    per_device_eval_batch_size=4,\n","    num_train_epochs=5,\n","    save_steps=10_000,\n","    save_total_limit=2,\n","    fp16=True,\n","    predict_with_generate=True,\n","    learning_rate=0.00017105019776419224,  # optimum learning rate found by hyperparameter tuning (using optuna)\n","    weight_decay=0.05238804154208795 # optimum weight decay found by hyperparameter tuning (using optuna)\n",")"]},{"cell_type":"markdown","metadata":{},"source":["#### Step 6: Intialize the trainer"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T17:51:20.705030Z","iopub.status.busy":"2024-08-29T17:51:20.704732Z","iopub.status.idle":"2024-08-29T17:51:21.625372Z","shell.execute_reply":"2024-08-29T17:51:21.624422Z","shell.execute_reply.started":"2024-08-29T17:51:20.704999Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"]}],"source":["trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_data['train'],\n","    eval_dataset=tokenized_data['dev'],\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"]},{"cell_type":"markdown","metadata":{},"source":["#### Step 7: Train the model"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T17:51:21.626959Z","iopub.status.busy":"2024-08-29T17:51:21.626658Z","iopub.status.idle":"2024-08-29T20:02:31.947917Z","shell.execute_reply":"2024-08-29T20:02:31.947054Z","shell.execute_reply.started":"2024-08-29T17:51:21.626927Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":["  ········································\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["wandb version 0.17.8 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.7"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/kaggle/working/wandb/run-20240829_175139-0lkki4kt</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/vinamra98-university-of-waterloo/huggingface/runs/0lkki4kt' target=\"_blank\">/kaggle/working/</a></strong> to <a href='https://wandb.ai/vinamra98-university-of-waterloo/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/vinamra98-university-of-waterloo/huggingface' target=\"_blank\">https://wandb.ai/vinamra98-university-of-waterloo/huggingface</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/vinamra98-university-of-waterloo/huggingface/runs/0lkki4kt' target=\"_blank\">https://wandb.ai/vinamra98-university-of-waterloo/huggingface/runs/0lkki4kt</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='4490' max='4490' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4490/4490 2:10:32, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Bert score f1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.831800</td>\n","      <td>0.004827</td>\n","      <td>89.607818</td>\n","      <td>0.9888</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.004400</td>\n","      <td>0.004769</td>\n","      <td>89.818564</td>\n","      <td>0.9893</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.003100</td>\n","      <td>0.005379</td>\n","      <td>90.199489</td>\n","      <td>0.9900</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.002100</td>\n","      <td>0.006171</td>\n","      <td>90.297948</td>\n","      <td>0.9899</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.001800</td>\n","      <td>0.007096</td>\n","      <td>90.346927</td>\n","      <td>0.9899</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a575a75f5b384125aea16c07370e107b","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e833a4092eeb4d809833a206a8cfaeff","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0a26b39886e44db6bc4ef888624d16b1","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4270216f4f6d48f4b244d41c2667f7da","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"09180828f3dc4c83b50cedcaa797e125","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e2cac7ed4a746269d05b638e42e1d14","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["calculating scores...\n","computing bert embedding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6d890d5bc64548888b05cfb4c10e8339","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["computing greedy matching.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"51a5b223986d459d9578741a83c006ed","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"0.9888\" of type <class 'str'> for key \"eval/Bert Score F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"name":"stdout","output_type":"stream","text":["done in 3.95 seconds, 253.47 sentences/sec\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["calculating scores...\n","computing bert embedding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3f223b6efccd41fc8c5692b863ed95b1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["computing greedy matching.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8f9b7c2feead49f880cd3bbdc0d3e528","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["done in 3.70 seconds, 269.98 sentences/sec\n"]},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"0.9893\" of type <class 'str'> for key \"eval/Bert Score F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["calculating scores...\n","computing bert embedding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2a2b6e5d3e9e4ae3a7b49b52ecd69ce2","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["computing greedy matching.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6e1735c7bb842c596b3e25e240f8ab5","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"0.9900\" of type <class 'str'> for key \"eval/Bert Score F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"name":"stdout","output_type":"stream","text":["done in 3.67 seconds, 272.23 sentences/sec\n"]},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["calculating scores...\n","computing bert embedding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e5d00a9684e946aaab9077f5b348cebf","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["computing greedy matching.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8e8a7ff27f11407182c039b1e3f59fa3","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["done in 3.65 seconds, 273.62 sentences/sec\n"]},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"0.9899\" of type <class 'str'> for key \"eval/Bert Score F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n","/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1258: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n","/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n","  warnings.warn('Was asked to gather along dimension 0, but all '\n","/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n","Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["calculating scores...\n","computing bert embedding.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6b01ce15a31c4a15998ee95c9abf5053","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/20 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["computing greedy matching.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"671828fd0cf44e9a98e7fbd9424cb568","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/16 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["done in 3.65 seconds, 274.25 sentences/sec\n"]},{"name":"stderr","output_type":"stream","text":["Trainer is attempting to log a value of \"0.9899\" of type <class 'str'> for key \"eval/Bert Score F1\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n"]},{"data":{"text/plain":["TrainOutput(global_step=4490, training_loss=0.09538775702361806, metrics={'train_runtime': 7869.6704, 'train_samples_per_second': 4.563, 'train_steps_per_second': 0.571, 'total_flos': 2.458963652640768e+16, 'train_loss': 0.09538775702361806, 'epoch': 5.0})"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-08-29T20:02:31.949828Z","iopub.status.busy":"2024-08-29T20:02:31.949352Z","iopub.status.idle":"2024-08-29T20:02:33.792104Z","shell.execute_reply":"2024-08-29T20:02:33.791182Z","shell.execute_reply.started":"2024-08-29T20:02:31.949782Z"},"trusted":true},"outputs":[],"source":["# Save the model and tokenizer\n","# model.save_pretrained(\"/kaggle/working/disfl-fine-tuned-FlanT5-model\")\n","# tokenizer.save_pretrained(\"/kaggle/working/disfl-fine-tuned-FlanT5-tokenizer\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":5599635,"sourceId":9255374,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
